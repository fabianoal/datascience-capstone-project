logSeatbelts <- glm(moreThen119 ~ kms + PetrolPrice + law, data=df, family="binomial")
exp(coef(logSeatbelts))
logSeatbelts$coeff
summary(logSeatbelts)
summary(logSeatbelts)$coefficients
exp(logSeatbelts$coefficients)
head(df)
df$tkms <- df$kms/1000
df$pp <- (df$PetrolPrice - mean(df$PetrolPrice))/sd(df$PetrolPrice)
df$tkmsc <- df$tkms - mean(df$tkms)
head(df)
logSeatbelts <- glm(moreThen119 ~ tkmsc + pp + law, data=df, family="binomial")
exp(logSeatbelts$coefficients)
summary(logSeatbelts)
fit2 <- glm(DriversKilled ~ tkmsc + pp + law, data=df, family="binomial")
tbl_df(df)
df
head(df)
fit2 <- glm(cbind(DriversKilled, drivers - DriversKilled) ~ tkmsc + pp + law, data=df, family="binomial")
fit2$coefficients
summary(fit2)
fit1 <- glm(moreThen119 ~ law, data=df, family="binomial")
fit2 <- glm(moreThen119 ~ law + pp, data=df, family="binomial")
fit3 <- glm(moreThen119 ~ law + pp + tkmsc, data=df, family="binomial")
aov(fit1,fit2, fit3)
anova(fit1,fit2,fit3)
summary(anova(fit1,fit2,fit3))
anova(fit1,fit2,fit3)
pfit1 <- glm(DriversKilled ~ tkmsc + pp + law, data=df, family="Poisson")
pfit1 <- glm(DriversKilled ~ tkmsc + pp + law, data=df, family="poisson")
pfit1$coefficients
fit1 <- lm(log(DriversKilled) ~ tkmsc + pp + law, data=df)
summary(fit1)
exp(1- 0.13)
exp(1 - -0.053968)
1- exp(0.13)
1 - exp(-0.13)
library(MASS)
?shuttle
s <- shuttle
s$useNumber <- 1 * (s$use == "auto")
table(s$useNumber)
fit0 <- glm(useNumber ~ wind, data=s, family="binomial")
summary(fit0)$coef
exp(summary(fit0)$coef[1,0])
summary(fit0)$coef[1,0]
summary(fit0)$coef[1,2]
summary(fit0)$coef[1,1]
summary(fit0)$coef[1,2]
summary(fit0)$coef[2,1]
exp(summary(fit0)$coef[2,1])
exp(summary(fit0)$coef[1,1])
help(relevel)
relevel(s$wind, "tail")
s$wind <- relevel(s$wind, "tail")
fit0 <- glm(useNumber ~ wind, data=s, family="binomial")
summary(fit0)$coef
exp(summary(fit0)$coef[2,1])
1 - exp(summary(fit0)$coef[2,1])
fit1 <- glm(useNumber ~ wind + magn, data=s, family="binomial")
summary(fit0)$coef
summary(fit1)$coef
exp(summary(fit1)$coef[2,1])
summary(fit0)$coef
summary(fit1)$coef
exp(summary(fit1)$coef[2,1])
exp(summary(fit0)$coef[2,1])
fit3 <- glm(fit0$fitted ~ wind, data=s, family="binomial")
fit0$fitted
fit3$coefficients
fit0$coefficients
head(InsectSprays)
glm(count ~ spray, data = InsectSprays, family = poisson)
fit4 <- glm(count ~ spray, data = InsectSprays, family = poisson)
summary(fit4)$coeff
exp(summary(fit4)$coeff[2,1])
is <- InsectSprays
is$spray <- relevel(is$spray, "B")
summary(fit4)$coeff
fit4 <- glm(count ~ spray, data = is, family = poisson)
summary(fit4)$coeff
exp(summary(fit4)$coeff[2,1])
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
knots <- c(0)
splineTerms <- sapply(knots, function(knot) (x > knot) * (x - knot)^2)
xMat <- cbind(1, x, splineTerms)
yhat <- predict(lm(y ~ xMat - 1))
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
xMat <- cbind(1, x, x^2, splineTerms)
yhat <- predict(lm(y ~ xMat - 1))
lines(x, yhat, col = "red", lwd = 2)
xMat <- cbind(1, x, x^3, splineTerms)
yhat <- predict(lm(y ~ xMat - 1))
lines(x, yhat, col = "red", lwd = 2)
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
summary(lm(y ~ xMat - 1))$coeff
cbind(1, x, x^3, splineTerms)
splineTerms
knots
knots <- c(0)
splineTerms <- sapply(knots, function(knot) (x > knot) * (x - knot)^2)
splineTerms
xMat
knots <- 0
knots <- 0
splineTerms <- sapply(knots, function(knot) (x > knot) * (x - knot)^2)
splineTerms
xMat <- cbind(1, x, splineTerms)
yhat <- predict(lm(y ~ xMat - 1))
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
xMat
xMat <- cbind(1, splineTerms)
yhat <- predict(lm(y ~ xMat - 1))
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
summary(lm(y ~ xMat - 1))$coeff
help(predict)
predict(lm(y ~ xMat - 1), newdata = c(0))
predict(lm(y ~ xMat - 1), newdata = as.data.frame(c(0)))
predict(lm(y ~ xMat - 1), newdata = as.data.frame(xMat = c(0)))
as.data.frame(xMat = c(0), x = c(0))
as.data.frame(xMat = c(0), x = c(0))
as.data.frame(c(xMat = 0, x = 0))
data.frame(c(xMat = 0, x = 0))
data.frame(xMat = c(0), x = c(0))
predict(lm(y ~ xMat - 1), newdata = data.frame(xMat = c(0), x = c(0)))
xMat
matrix(c(0), c(0))
help("matrix")
matrix(c(0,0), nrow=1, ncol=2)
predict(lm(y ~ xMat - 1), newdata = matrix(c(0,0), nrow=1, ncol=2))
predict(lm(y ~ xMat - 1), newdata = as.data.frame(matrix(c(0,0), nrow=1, ncol=2)))
summary(lm(y ~ xMat - 1))$coeff
splineTerms
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
summary(lm(y ~ xMat - 1))
fit <- lm(y ~ xMat - 1)
fit$terms
fit$fitted.values
fit$fitted.values[6]
fit$fitted.values[7]
fit$fitted.values[7] - fit$fitted.values[6]
yhat <- predict(lm(y ~ xMat))
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
splineTerms
splineTerms <- sapply(knots, function(knot) (x > knot) * (y - knot)^2)
splineTerms
xMat <- cbind(1, splineTerms)
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
fit <- lm(y ~ xMat - 1)
fit$fitted.values[7] - fit$fitted.values[6]
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
library(caret)
rf <- train(y~., data=vowel.train, method="rf")
gbm <- train(y~., method="gbm", data=vowel.train, verbose=F)
pred1<- predict(rf, newdata = vowel.test)
pred2 <- predict(gbm, newdata = vowel.test)
result <- data.frame(pred1, pred2, vowel.test$y)
rownames(result) <- c("pred1_rf","pred_gbm", "result")
head(result)
colnames(result) <- c("pred1_rf","pred_gbm", "value")
head(result)
library(dplyr)
result %>%
filter(pred1_rf == pred2_gbm)
colnames(result) <- c("pred_rf","pred_gbm", "value")
result %>%
filter(pred_rf == pred2_gbm)
result %>%
filter(pred_rf == pred_gbm)
result %>%
filter(pred_rf == pred_gbm) %>%
select(c("pred_gbm","value"))
result %>%
filter(pred_rf == pred_gbm) %>%
select("pred_gbm","value")
result %>%
filter(pred_rf == pred_gbm) %>%
select(pred_gbm,value)
confusionMatrix(
result %>%
filter(pred_rf == pred_gbm) %>%
select(pred_gbm,value)
)
filteredResult <- result %>%
filter(pred_rf == pred_gbm) %>%
select(pred_gbm,value)
confusionMatrix(filteredResult$pred_gbm, filteredResult$value)
confusionMatrix(vowel.test$y, pred1)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
rf <- train(y~., data=vowel.train, method="rf")
gbm <- train(y~., method="gbm", data=vowel.train)
gbm <- train(y~., method="gbm", data=vowel.train, verbose=F)
pred1 <- predict(rf, newdata = vowel.test)
pred2 <- predict(gbm, newdata = vowel.test)
confusionMatrix(vowel.test$y, pred1)
confusionMatrix(vowel.test$y, pred2)
result <- data.frame(pred1, pred2, vowel.test$y)
colnames(result) <- c("pred_rf","pred_gbm", "value")
filteredResult <- result %>%
filter(pred_rf == pred_gbm) %>%
select(pred_gbm,value)
confusionMatrix(filteredResult$value, filteredResult$pred_gbm)
confusionMatrix(vowel.test$y, pred1)
confusionMatrix(vowel.test$y, pred2)
confusionMatrix(filteredResult$value, filteredResult$pred_gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fitRf <- train(diagnosis~., data=training, method="rf")
fitGbm <- train(diagnosis~., data=trainig, method="gbm")
fitGbm <- train(diagnosis~., data=training, method="gbm")
fitGbm <- train(diagnosis~., data=training, method="gbm", verbose=FALSE)
fitLda <- train(diagnosis~., data=training, method="lda", verbose=FALSE)
predRf <- predict(fitRf, newdata = testing)
predGbm <- predict(fitGbm, newdata = testing)
predLda <- predict(fitLda, newdata = testing)
confusionMatrix(testing$diagnosis, predRF)$accuracy
confusionMatrix(testing$diagnosis, predRf)$accuracy
summary(confusionMatrix(testing$diagnosis, predRf))
confusionMatrix(testing$diagnosis, predRf)
confusionMatrix(testing$diagnosis, predGbm) #.78
confusionMatrix(testing$diagnosis, predLda) #.78
stacked <- data.frame(predRf, predGbm, predLda, testing$diagnosis)
colnames(stacked) <- c("predRf", "predGbm", "predLda","diagnosis")
colnames(stacked) <- c("predRf", "predGbm", "predLda","diagnosis")
fitStackedRf <- train(diagnosis ~ .,data=stacked, method="rf")
confusionMatrix(testing$diagnosis, predict(fitStackedRf))
confusionMatrix(testing$diagnosis, predict(fitStackedRf, newdata = fitStackedRf))
confusionMatrix(testing$diagnosis, predict(fitStackedRf, newdata = stacked))
predRf <- predict(fitRf, newdata = training)
predGbm <- predict(fitGbm, newdata = training)
predLda <- predict(fitLda, newdata = training)
stacked <- data.frame(predRf, predGbm, predLda, training$diagnosis)
colnames(stacked) <- c("predRf", "predGbm", "predLda","diagnosis")
fitStackedRf <- train(diagnosis ~ ., data=stacked, method="rf")
confusionMatrix(testing$diagnosis, predict(fitStackedRf, newdata = stacked)) #0.82
predRf.test <- predit(fitRf, newdata = testing)
predRf.test <- predict(fitRf, newdata = testing)
predGbm.test <- predict(fitGbm, newdata = testing)
predLda.test <- predict(fitLda, newdata = testing)
stacked.testing <- data.frame(predRf.test, predGbm.test, predLda.test, testing$diagnosis)
stacked.testing <- data.frame(predRf.test, predGbm.test, predLda.test, testing$diagnosis)
colnames(stacked.testing) <- c("predRf", "predGbm", "predLda","diagnosis")
confusionMatrix(testing$diagnosis, predict(fitStackedRf, newdata = stacked.testing)) #0.82
confusionMatrix(testing$diagnosis, predict(fitGbm, newdata = testing)) #.80
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
install.packages("lars")
library(lars)
head(concrete)
lasso.fit <- train(CompressiveStrength~., data=training, method="lasso", preProcess=c("center","scale"))
plot(lasso.fit, breaks=FALSE, cex = 0.75)
plot(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
legend("topleft", covnames, pch=8, lty=1:length(covnames),
col=1:length(covnames), cex = 0.6)
legend("topleft", training, pch=8, lty=1:length(training),col=1:length(training), cex = 0.6)
plot(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
lasso.fit <- train(CompressiveStrength~., data=training, method="lasso")
plot(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
lasso.fit <- train(CompressiveStrength~., data=training, method="lasso", preProcess=c("center","scale"))
plot(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
lasso.fit$finalModel$lambda
head(concrete)
lasso.fit <- train(CompressiveStrength~., data=training, method="lasso", preProcess=c("center","scale"))
lasso.fit$finalModel$lambda
plot(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
colNames(training)
colnames(training)
legend("topleft", training, pch=8, lty=1:length(colnames(training)),col=1:length(colnames(training)), cex = 0.6)
legend("topleft", colnames(training), pch=8, lty=1:length(colnames(training)),col=1:length(colnames(training)), cex = 0.6)
plot(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
plot(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
# add legend
legend("topleft", colnames(training), pch=8, lty=1:length(colnames(training)),col=1:length(colnames(training)), cex = 0.6)
warnings()
plot.enet(lasso.fit$finalModel, breaks=FALSE, cex = 0.75)
plot.enet(lasso.fit$finalModel,cex = 0.75)
warnings()
summary(lasso.fit$finalModel)
summary(lasso.fit$finalModel)$coef
plot(lasso.fit$finalModel,cex = 0.75)
plot(lasso.fit$finalModel,cex = 0.8, breaks=TRUE)
library(lars)
library(lars)
plot(lasso.fit$finalModel,cex = 0.8)
lasso.fit <- lars(as.matrix(concrete[,-c("CompressiveStrength")]), concrete$CompressiveStrength, type="lasso", trace=true)
lasso.fit <- lars(as.matrix(concrete[,-c("CompressiveStrength")]), concrete$CompressiveStrength, type="lasso", trace=TRUE)
concrete[,-c("CompressiveStrength")]
concrete[,-"CompressiveStrength"]
concrete[,c(-"CompressiveStrength")]
concrete[,-c("CompressiveStrength")]
concrete[,c("CompressiveStrength")]
concrete[,c(-"CompressiveStrength")]
c("x","a") - c("a")
head(concrete)
concrete[,1:8]
head(concrete[,1:8])
lasso.fit <- lars(as.matrix(concrete[,1:8]), concrete$CompressiveStrength, type="lasso", trace=TRUE)
plot(lasso.fit$finalModel,cex = 0.8)
plot(lasso.fit$finalModel,cex = 0.8, breaks=TRUE)
?plot.enet
plot(lasso.fit,cex = 0.8, breaks=TRUE)
legend("topleft", colnames(training), pch=8, lty=1:length(colnames(training)),col=1:length(colnames(training)), cex = 0.6)
plot(lasso.fit, xvar=c("penalty"), cex = 0.8, breaks=TRUE)
plot(lasso.fit, xvar="penalty", cex = 0.8, breaks=TRUE)
plot(lasso.fit, xvar="penalty")
plot(lasso.fit, xvar=c("penalty"))
plot.enet(lasso.fit, xvar=c("penalty"))
plot.enet(lasso.fit, xvar=c("penalty"))
plot(lasso.fit,cex = 0.8, breaks=TRUE)
summary(lasso.fit)
?plot.enet
plot(lasso.fit)
plot(lasso.fit, xvar=step)
plot(lasso.fit, xvar="step")
plot(lasso.fit, xvar="penalty")
plot.enet(lasso.fit, xvar="penalty")
plot(lasso.fit, xvar="step")
plot(lasso.fit, xvar="lambda")
plot(lasso.fit, xvar="norm")
lasso.fit <- lars(as.matrix(concrete[,1:8]), concrete$CompressiveStrength, type="lasso", trace=TRUE)
summary(lasso.fit)
enet()
enet.fit <- enet(as.matrix(concrete[,1:8]), concrete$CompressiveStrength, lambda=0)
plot(enet.fit)
plot(enet.fit, xvar="penalty")
?plot.enet
plot(enet.fit, xvar="penalty", use.color = TRUE)
legend("topright", colnames(training), pch=8, lty=1:length(colnames(training)),col=1:length(colnames(training)), cex = 0.6)
library(lubridate) # For year() function below
getwd()
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(url, "Users/fabianoal/Documents/GitHub/My-Coursera-Data-Science-Projects/Pratical Machine Learning/gaData.csv" )
download.file(url, "/Users/fabianoal/Documents/GitHub/My-Coursera-Data-Science-Projects/Pratical Machine Learning/gaData.csv" )
library(lubridate) # For year() function below
dat = read.csv("/Users/fabianoal/Documents/GitHub/My-Coursera-Data-Science-Projects/Pratical Machine Learning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
??bats
library(forecast)
head(training)
bats.fit <- bats(training)
bats.fit <- bats(training$visitsTumblr)
??forecast
help(forecast)
forecast(bats.fit, level = 0.95)
forecast(bats.fit)
plot(bats.fit)
forecast(bats.fit, newData = testing)
dim(testing)
forecast(bats.fit, h=235)
pred <- forecast(bats.fit, h=235)
pred$rval <- testing$visitsTumblr
head(pred)
??foreast
??forecast
forecast::accuracy(bats.fit, testing$visitsTumblr)
pred <- forecast(bats.fit, h=235)
summary(pred)
summary(pred)$forecasts
summary(pred)$Forecasts
head(pred)
pred$rval <- testing$visitsTumblr
summary(pred)$Forecasts
pred <- forecast(bats.fit, h=235)
pred$Forecasts
pred[[3]]
pred[[4]]
pred[[5]]
pred[[5]][,2]
pred[[6]]
pred
pred[[6]]
pred[[5]][,2]
nrows(testing)
rows(testing)
nrow(testing)
bats.fit <- bats(training$visitsTumblr)
pred <- forecast(bats.fit, h=nrow(testing))
pred[[5]][,2]
pred[[6]][,2]
resultIn95 <- testing$visitsTumblr >= pred[[6]][,2] && testing$visitsTumblr <= pred[[5]][,2]
table(resultIn95)
testing$visitsTumblr >= pred[[6]][,2] && testing$visitsTumblr <= pred[[5]][,2]
testing$visitsTumblr
testing$visitsTumblr >= pred[[6]][,2]
testing$visitsTumblr <= pred[[5]][,2]
testing$visitsTumblr >= pred[[6]][,2] && testing$visitsTumblr <= pred[[5]][,2]
testing$visitsTumblr >= pred[[6]][,2] & testing$visitsTumblr <= pred[[5]][,2]
resultIn95 <- testing$visitsTumblr >= pred[[6]][,2] & testing$visitsTumblr <= pred[[5]][,2]
table(resultIn95)
sum(resultIn95)
sum(resultIn95)/nrow(training)
sum(resultIn95)/nrow(training)
table(resultIn95)
sum(resultIn95)/nrow(testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
??e1071
install.packages("e1071")
install.packages("e1071")
??e1071
library(e1071)
hep(svm)
help(svm)
svm.fit <- svm(CompressiveStrength~., data = training)
svm.pred <- predict(svm.fit, testing)
sqrt(sum((svm.pred-testing$CompressiveStrength)^2))
help(sample)
getSampleFromFile <- function(fileName, samplePerc){
f <- file(fileName)
lines <- readLines(f, open="r")
close(f)
lines[floor(sample(length(lines) * samplePerc)]
}
getSampleFromFile <- function(fileName, samplePerc){
f <- file(fileName)
lines <- readLines(f, open="r")
close(f)
lines[floor(sample(length(lines) * samplePerc))]
}
#Function to get a sample from the files
getSampleFromFile <- function(fileName, samplePerc){
print(paste0("Getting sample from file ", fileName))
f <- file(fileName)
lines <- readLines(f, open="r")
close(f)
lines[floor(sample(length(lines) * samplePerc))]
}
tokenizeTexts <- function(filesLocation, cacheLocation, samplePerc){
cname <- paste0(getwd(),filesLocation)
files <- paste(cname, list.files(cname), sep="/")
cacheDir <- paste(getwd(), cacheLocation, sep="/")
s <- vector(mode = 'character')
ngrams <- c(4,3,2)
for (j in files){
print(paste0("Processing file ", j))
lines <- getSampleFromFile(j, samplePerc)
for (ng in ngrams){
outFile <- paste(cacheDir,sub("\\.txt", paste0(".tokenized", as.character(ng),".Rdata"), sub("/.*/","", j)), sep = "/")
print(paste0("Dest file: ", outFile))
outFile <- gzfile(outFile, open="wb")
res <- tokenize(lines, removeNumbers = TRUE, removePunct = TRUE, removeSeparators = TRUE, removeTwitter = TRUE, ngrams = ng, simplify = TRUE)
save(res,file = outFile)
rm(res)
close(outFile)
}
}
}
tokenizeTexts(textFilesLocation, cacheFolder, 0.01)
library(quanteda)
library(wordcloud)
library(stringi)
library(ggplot2)
library(scales)
library(caret)
library(dplyr)
library(Matrix)
library(reshape2)
ngramregex <- "_[^_]*?$"
predregex  <- "^.*_"
setwd("/Users/fabianoal/Documents/GitHub/Data Science Capstone Project")
textFilesLocation <- "/final/en_US"
cacheFolder <- "/cache/"
set.seed(3546)
tokenizeTexts(textFilesLocation, cacheFolder, 0.01)
getSampleFromFile <- function(fileName, samplePerc){
print(paste0("Getting sample from file ", fileName))
f <- file(fileName, open="r")
lines <- readLines(f)
close(f)
lines[floor(sample(length(lines) * samplePerc))]
}
tokenizeTexts(textFilesLocation, cacheFolder, 0.01)
help(dfm)
help(mutate)
